{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6bd69a-3b4f-4243-8010-e767ec036cfb",
   "metadata": {},
   "source": [
    "##### Understanding Frontmatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64b5f600-afdb-4258-881a-06fa7409df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Started with AI\n",
      "Euriel Chukwu\n",
      "2025-09-23\n",
      "['ai', 'machine-learning', 'tutorial']\n",
      "beginner\n",
      "# Welcome\n",
      "\n",
      "This is a tutorial on getting started with AI Agent.\n"
     ]
    }
   ],
   "source": [
    "import frontmatter\n",
    "\n",
    "raw = \"\"\"---\n",
    "title: \"Getting Started with AI\"\n",
    "author: \"Euriel Chukwu\"\n",
    "date: \"2025-09-23\"\n",
    "tags: [\"ai\", \"machine-learning\", \"tutorial\"]\n",
    "difficulty: \"beginner\"\n",
    "---\n",
    "\n",
    "# Welcome\n",
    "\n",
    "This is a tutorial on getting started with AI Agent.\n",
    "\"\"\"\n",
    "\n",
    "post = frontmatter.loads(raw)\n",
    "\n",
    "print(post.metadata['title'])  # \"Getting Started with AI\"\n",
    "print(post.metadata['author'])\n",
    "print(post.metadata['date'])\n",
    "print(post.metadata['tags'])   # [\"ai\", \"machine-learning\", \"tutorial\"]\n",
    "print(post.metadata['difficulty'])\n",
    "print(post.content)            # Markdown content without frontmatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbc98c-24b9-41dc-b6fb-b03ebe7db6d3",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3578f57c-5871-45a0-a214-dfc9dadd917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c455a-2c30-4a13-ad28-aede4a490efe",
   "metadata": {},
   "source": [
    "Download repository as a zip file using github URL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb308ca2-50c7-432c-8e05-b6fc88f32ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeload.github.com/ceuriel/atlite/zip/refs/heads/master'\n",
    "resp = requests.get(url)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560377db-3ee6-41d9-b09b-8bbf120b7f6c",
   "metadata": {},
   "source": [
    "Process the zip file in memory without saving to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67cf8b6d-fb49-4ab9-8258-b0429a28f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_data = []\n",
    "\n",
    "# Create a ZipFile object from the downloaded content\n",
    "zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "\n",
    "for file_info in zf.infolist():\n",
    "    filename = file_info.filename.lower()\n",
    "\n",
    "    # Only process markdown files\n",
    "    if not filename.endswith('.md'):\n",
    "        continue\n",
    "\n",
    "    # Read and parse each file\n",
    "    with zf.open(file_info) as f_in:\n",
    "        content = f_in.read()\n",
    "        post = frontmatter.loads(content)\n",
    "        data = post.to_dict()\n",
    "        data['filename'] = filename\n",
    "        repository_data.append(data)\n",
    "\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca68dc-e7cf-4bb9-b7e4-bc41ee3a26c8",
   "metadata": {},
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2150c64c-a13c-4a37-9443-d44f84f88bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"<!--\\nSPDX-FileCopyrightText: Contributors to atlite <https://github.com/pypsa/atlite>\\n\\nSPDX-License-Identifier: CC0-1.0\\n-->\\n\\nCloses # (if applicable).\\n\\n## Changes proposed in this Pull Request\\n\\n\\n## Checklist\\n\\n- [ ] Code changes are sufficiently documented; i.e. new functions contain docstrings and further explanations may be given in `doc`.\\n- [ ] Unit tests for new features were added (if applicable).\\n- [ ] Newly introduced dependencies are added to `environment.yaml`, `environment_docs.yaml` and `setup.py` (if applicable).\\n- [ ] A note for the release notes `doc/release_notes.rst` of the upcoming release is included.\\n- [ ] I consent to the release of this PR's code under the MIT license.\", 'filename': 'atlite-master/.github/pull_request_template.md'}\n"
     ]
    }
   ],
   "source": [
    "print(repository_data[1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919e510-3ef6-411a-b868-b13c60fd28d1",
   "metadata": {},
   "source": [
    " ### Complete implementation in a reusable function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1652dcb4-703d-4513-9b88-88dee788b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/master'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccd1c6-d9f6-4a48-836b-b96432e901fc",
   "metadata": {},
   "source": [
    "Function can be used for different repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "987acd6f-67b8-48b4-b75e-491a64695402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlite documents: 3\n",
      "h2o-3 documents: 89\n"
     ]
    }
   ],
   "source": [
    "h2oai = read_repo_data('h2oai', 'h2o-3')\n",
    "ceuriel_atlite = read_repo_data('ceuriel', 'atlite')\n",
    "\n",
    "print(f\"Atlite documents: {len(ceuriel_atlite)}\")\n",
    "print(f\"h2o-3 documents: {len(h2oai)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "043638ca-5d35-4563-b935-ec04be868a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2o-3-master/.github/ISSUE_TEMPLATE/bug_report.md\n",
      "h2o-3-master/.github/ISSUE_TEMPLATE/feature_request.md\n",
      "h2o-3-master/CONTRIBUTING.md\n",
      "h2o-3-master/Changes-prior-3.28.0.1.md\n",
      "h2o-3-master/Changes.md\n",
      "h2o-3-master/DEVEL.md\n",
      "h2o-3-master/README.md\n",
      "h2o-3-master/README_DATA.md\n",
      "h2o-3-master/SECURITY.md\n",
      "h2o-3-master/ec2/README.md\n",
      "h2o-3-master/examples/deeplearning/notebooks/README.md\n",
      "h2o-3-master/gradle/README.md\n",
      "h2o-3-master/h2o-algos/src/main/java/hex/deeplearning/README.md\n",
      "h2o-3-master/h2o-assemblies/main/README.md\n",
      "h2o-3-master/h2o-assemblies/minimal/README.md\n",
      "h2o-3-master/h2o-bindings/bin/readme.md\n",
      "h2o-3-master/h2o-clustering/README.md\n",
      "h2o-3-master/h2o-core/src/main/resources/docs/pieces/columnSummary.md\n",
      "h2o-3-master/h2o-dist/README.md\n",
      "h2o-3-master/h2o-docs/README.md\n",
      "h2o-3-master/h2o-docs/StyleGuide.md\n",
      "h2o-3-master/h2o-docs/src/api/README.md\n",
      "h2o-3-master/h2o-docs/src/api/REST/h2o_3_rest_api_overview.md\n",
      "h2o-3-master/h2o-docs/src/api/data-science-example-1/README.md\n",
      "h2o-3-master/h2o-docs/src/api/data-science-example-1/example-flow.md\n",
      "h2o-3-master/h2o-docs/src/api/rest-api-error-handling/README.md\n",
      "h2o-3-master/h2o-docs/src/booklets/source/DeepWaterBookletErrata.md\n",
      "h2o-3-master/h2o-docs/src/booklets/v2_2015/source/LaTeX_StyleGuide.md\n",
      "h2o-3-master/h2o-docs/src/cheatsheets/H2O_R_Python_Parity.md\n",
      "h2o-3-master/h2o-docs/src/cheatsheets/Python_H2OFrame_PandasDataFrame_Parity.md\n",
      "h2o-3-master/h2o-docs/src/dev/README.md\n",
      "h2o-3-master/h2o-docs/src/dev/custom_functions.md\n",
      "h2o-3-master/h2o-docs/src/dev/lifecycle.md\n",
      "h2o-3-master/h2o-docs/src/front/README.md\n",
      "h2o-3-master/h2o-docs/src/front/assets/fonts/Heebo/README.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/README.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/RecentChanges.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/SiteIntro.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/packs/examples/readme.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/Connecting_RStudio_to_Sparkling_Water.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/DemosAndTests.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/FAQ.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevCmdLine.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevDocker.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevHadoop.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevLogs.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevS3Creds.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-Networking.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/LDAP.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/MOJO_QuickStart.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/POJO_QuickStart.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/Videos.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/YARN_BP.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/GainsLift.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/GridSearch.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/Interactions.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/datascience/DataScienceH2O-Dev.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/dl/dl.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/gbm/gbm.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/glm/glm.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/glossary.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/kmeans/kmeans.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/pca/pca.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/random hyperparmeter search and roadmap.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/rf/rf.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/H2OBenefits.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/H2ODevPortingRScripts.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/JavaChanges.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/Migration.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/PressRelease.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/PythonParity.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/RChanges.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/Rdoc.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/Upgrade.md\n",
      "h2o-3-master/h2o-genmodel/src/test/resources/hex/genmodel/algos/glrm/experimental/README.md\n",
      "h2o-3-master/h2o-genmodel/src/test/resources/hex/genmodel/algos/isofor/experimental/README.md\n",
      "h2o-3-master/h2o-genmodel/src/test/resources/hex/genmodel/algos/isoforextended/experimental/README.md\n",
      "h2o-3-master/h2o-k8s/README.md\n",
      "h2o-3-master/h2o-k8s/tests/clustering/README.md\n",
      "h2o-3-master/h2o-py-cloud-extensions/README.md\n",
      "h2o-3-master/h2o-py/README.md\n",
      "h2o-3-master/h2o-py/demos/README.md\n",
      "h2o-3-master/h2o-r/README.md\n",
      "h2o-3-master/h2o-r/demos/README.md\n",
      "h2o-3-master/h2o-r/ensemble/README.md\n",
      "h2o-3-master/h2o-web/README.md\n",
      "h2o-3-master/templates/gcp/README.md\n",
      "h2o-3-master/templates/gcp/network/README.md\n",
      "h2o-3-master/vagrant/README.md\n"
     ]
    }
   ],
   "source": [
    "for record in h2oai:\n",
    "    print(record['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e91e779-3920-40aa-809e-5943c9d39cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlite-master/.github/ISSUE_TEMPLATE/feature_request.md\n",
      "atlite-master/.github/pull_request_template.md\n",
      "atlite-master/CONTRIBUTING.md\n"
     ]
    }
   ],
   "source": [
    "for record in ceuriel_atlite:\n",
    "    print(record['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44860ee-be75-458e-9cf5-0fd162302309",
   "metadata": {},
   "source": [
    "#### Simple Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dbc13-3edf-4b26-a8f5-8b32e7991626",
   "metadata": {},
   "source": [
    "Applying Sliding window method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6a721f1-65a9-4882-9c1a-3ceb39b29ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60632ee8-c7ac-4a6a-b9b6-3baeda152686",
   "metadata": {},
   "source": [
    "Process the entire documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5edea32a-629d-4895-a7a9-e51b713f6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2oai_chunks = []\n",
    "\n",
    "for doc in h2oai:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    chunks = sliding_window(doc_content, 2000, 1000)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    h2oai_chunks.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7dd9d2f-4df1-4c4d-a4b2-d20df31a0f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 1639\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total chunks: {len(h2oai_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729b6d2-86d5-4640-a519-ea4f7e898907",
   "metadata": {},
   "source": [
    "#### Splitting by Paragraphs and Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772630f-03c9-4eb3-8b8d-a7dff588b106",
   "metadata": {},
   "source": [
    "splitting by paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e452c5f-431c-491f-ba17-f7b8ff6f3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = h2oai[45]['content']\n",
    "paragraphs = re.split(r\"\\n\\s*\\n\", text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447e89c-623e-4ac5-91f1-b509b379b267",
   "metadata": {},
   "source": [
    "splitting by section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df897ae4-659c-4584-983d-4910fdfde3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_markdown_by_level(text, level=2):\n",
    "    \"\"\"\n",
    "    Split markdown text by a specific header level.\n",
    "    \n",
    "    :param text: Markdown text as a string\n",
    "    :param level: Header level to split on\n",
    "    :return: List of sections as strings\n",
    "    \"\"\"\n",
    "    # This regex matches markdown headers\n",
    "    # For level 2, it matches lines starting with \"## \"\n",
    "    header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "    pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "\n",
    "    # Split and keep the headers\n",
    "    parts = pattern.split(text)\n",
    "    \n",
    "    sections = []\n",
    "    for i in range(1, len(parts), 3):\n",
    "        # We step by 3 because regex.split() with\n",
    "        # capturing groups returns:\n",
    "        # [before_match, group1, group2, after_match, ...]\n",
    "        # here group1 is \"## \", group2 is the header text\n",
    "        header = parts[i] + parts[i+1]  # \"## \" + \"Title\"\n",
    "        header = header.strip()\n",
    "\n",
    "        # Get the content after this header\n",
    "        content = \"\"\n",
    "        if i+2 < len(parts):\n",
    "            content = parts[i+2].strip()\n",
    "\n",
    "        if content:\n",
    "            section = f'{header}\\n\\n{content}'\n",
    "        else:\n",
    "            section = header\n",
    "        sections.append(section)\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7123d0-af7a-4a24-bc97-6ac8f9cd7bd1",
   "metadata": {},
   "source": [
    "Final result by iterating over all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f77be44-4738-4147-9af4-ad2c2727a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2oai_chunks = []\n",
    "\n",
    "for doc in h2oai:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    sections = split_markdown_by_level(doc_content, level=2)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        h2oai_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "07a64a91-8ac7-4e43-8a31-14e23d0d36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 266\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total chunks: {len(h2oai_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48085a8e-fa2b-4dde-afb5-a0f4606524e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfd76a95-6a55-48a4-b932-00a8d8488182",
   "metadata": {},
   "source": [
    "#### Intelligent Chunking with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e980788-d742-4446-8c97-a79359fd0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET API key from https://platform.openai.com/api-keys\n",
    "# create an environment variable with your key:\n",
    "# from command line run:\n",
    "# export OPENAI_API_KEY='your-api-key'\n",
    "# uv add openai\n",
    "# uv run jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43a660db-488f-431c-acd1-7ab142f0628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4.1-mini'):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e2014-d31b-4d8c-bf35-610cee83ac5c",
   "metadata": {},
   "source": [
    "##### Create a prompt\n",
    "\n",
    "The prompt asks the LLM to:\n",
    "\n",
    "Split the document logically (not just by length)\n",
    "\n",
    "Make sections self-contained\n",
    "\n",
    "Use a specific output format that's easy to parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3704f58b-d993-4840-aa2b-0acd60f4d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Split the provided document into logical sections\n",
    "that make sense for a Q&A system.\n",
    "\n",
    "Each section should be self-contained and cover\n",
    "a specific topic or concept.\n",
    "\n",
    "<DOCUMENT>\n",
    "{document}\n",
    "</DOCUMENT>\n",
    "\n",
    "Use this format:\n",
    "\n",
    "## Section Name\n",
    "\n",
    "Section content with all relevant details\n",
    "\n",
    "---\n",
    "\n",
    "## Another Section Name\n",
    "\n",
    "Another section content\n",
    "\n",
    "---\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fedcd-eb05-406f-b917-9a57b60e82c3",
   "metadata": {},
   "source": [
    "##### Create a function for intelligent chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f256fd0-6882-47cc-8ea8-fde2f0529632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intelligent_chunking(text):\n",
    "    prompt = prompt_template.format(document=text)\n",
    "    response = llm(prompt)\n",
    "    sections = response.split('---')\n",
    "    sections = [s.strip() for s in sections if s.strip()]\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36d33e-3e61-4bca-a267-2286288c0e1f",
   "metadata": {},
   "source": [
    "##### Apply to entire document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f73fa-7068-434e-b0e2-2d23a61d6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "h2oai_chunks = []\n",
    "\n",
    "for doc in tqdm(h2oai):\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "\n",
    "    sections = intelligent_chunking(doc_content)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        h2oai_chunks.append(section_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaffc6d-4782-4527-86e5-66a702b96929",
   "metadata": {},
   "source": [
    "##### Note: This process requires time and incurs costs. As mentioned before, use this only when really necessary. For most applications, you don't need intelligent chunking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414e488-0c00-491c-9a2a-8c816ca85d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
