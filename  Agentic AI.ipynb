{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6bd69a-3b4f-4243-8010-e767ec036cfb",
   "metadata": {},
   "source": [
    "##### Understanding Frontmatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b5f600-afdb-4258-881a-06fa7409df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Started with AI\n",
      "Euriel Chukwu\n",
      "2025-09-23\n",
      "['ai', 'machine-learning', 'tutorial']\n",
      "beginner\n",
      "# Welcome\n",
      "\n",
      "This is a tutorial on getting started with AI Agent.\n"
     ]
    }
   ],
   "source": [
    "import frontmatter\n",
    "\n",
    "raw = \"\"\"---\n",
    "title: \"Getting Started with AI\"\n",
    "author: \"Euriel Chukwu\"\n",
    "date: \"2025-09-23\"\n",
    "tags: [\"ai\", \"machine-learning\", \"tutorial\"]\n",
    "difficulty: \"beginner\"\n",
    "---\n",
    "\n",
    "# Welcome\n",
    "\n",
    "This is a tutorial on getting started with AI Agent.\n",
    "\"\"\"\n",
    "\n",
    "post = frontmatter.loads(raw)\n",
    "\n",
    "print(post.metadata['title'])  # \"Getting Started with AI\"\n",
    "print(post.metadata['author'])\n",
    "print(post.metadata['date'])\n",
    "print(post.metadata['tags'])   # [\"ai\", \"machine-learning\", \"tutorial\"]\n",
    "print(post.metadata['difficulty'])\n",
    "print(post.content)            # Markdown content without frontmatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbc98c-24b9-41dc-b6fb-b03ebe7db6d3",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3578f57c-5871-45a0-a214-dfc9dadd917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c455a-2c30-4a13-ad28-aede4a490efe",
   "metadata": {},
   "source": [
    "Download repository as a zip file using github URL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb308ca2-50c7-432c-8e05-b6fc88f32ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeload.github.com/ceuriel/atlite/zip/refs/heads/master'\n",
    "resp = requests.get(url)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560377db-3ee6-41d9-b09b-8bbf120b7f6c",
   "metadata": {},
   "source": [
    "Process the zip file in memory without saving to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cf8b6d-fb49-4ab9-8258-b0429a28f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_data = []\n",
    "\n",
    "# Create a ZipFile object from the downloaded content\n",
    "zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "\n",
    "for file_info in zf.infolist():\n",
    "    filename = file_info.filename.lower()\n",
    "\n",
    "    # Only process markdown files\n",
    "    if not filename.endswith('.md'):\n",
    "        continue\n",
    "\n",
    "    # Read and parse each file\n",
    "    with zf.open(file_info) as f_in:\n",
    "        content = f_in.read()\n",
    "        post = frontmatter.loads(content)\n",
    "        data = post.to_dict()\n",
    "        data['filename'] = filename\n",
    "        repository_data.append(data)\n",
    "\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca68dc-e7cf-4bb9-b7e4-bc41ee3a26c8",
   "metadata": {},
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2150c64c-a13c-4a37-9443-d44f84f88bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"<!--\\nSPDX-FileCopyrightText: Contributors to atlite <https://github.com/pypsa/atlite>\\n\\nSPDX-License-Identifier: CC0-1.0\\n-->\\n\\nCloses # (if applicable).\\n\\n## Changes proposed in this Pull Request\\n\\n\\n## Checklist\\n\\n- [ ] Code changes are sufficiently documented; i.e. new functions contain docstrings and further explanations may be given in `doc`.\\n- [ ] Unit tests for new features were added (if applicable).\\n- [ ] Newly introduced dependencies are added to `environment.yaml`, `environment_docs.yaml` and `setup.py` (if applicable).\\n- [ ] A note for the release notes `doc/release_notes.rst` of the upcoming release is included.\\n- [ ] I consent to the release of this PR's code under the MIT license.\", 'filename': 'atlite-master/.github/pull_request_template.md'}\n"
     ]
    }
   ],
   "source": [
    "print(repository_data[1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919e510-3ef6-411a-b868-b13c60fd28d1",
   "metadata": {},
   "source": [
    " ### Complete implementation in a reusable function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1652dcb4-703d-4513-9b88-88dee788b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/master'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccd1c6-d9f6-4a48-836b-b96432e901fc",
   "metadata": {},
   "source": [
    "Function can be used for different repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "987acd6f-67b8-48b4-b75e-491a64695402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlite documents: 3\n",
      "h2o-3 documents: 89\n"
     ]
    }
   ],
   "source": [
    "h2oai = read_repo_data('h2oai', 'h2o-3')\n",
    "ceuriel_atlite = read_repo_data('ceuriel', 'atlite')\n",
    "\n",
    "print(f\"Atlite documents: {len(ceuriel_atlite)}\")\n",
    "print(f\"h2o-3 documents: {len(h2oai)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "043638ca-5d35-4563-b935-ec04be868a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2o-3-master/.github/ISSUE_TEMPLATE/bug_report.md\n",
      "h2o-3-master/.github/ISSUE_TEMPLATE/feature_request.md\n",
      "h2o-3-master/CONTRIBUTING.md\n",
      "h2o-3-master/Changes-prior-3.28.0.1.md\n",
      "h2o-3-master/Changes.md\n",
      "h2o-3-master/DEVEL.md\n",
      "h2o-3-master/README.md\n",
      "h2o-3-master/README_DATA.md\n",
      "h2o-3-master/SECURITY.md\n",
      "h2o-3-master/ec2/README.md\n",
      "h2o-3-master/examples/deeplearning/notebooks/README.md\n",
      "h2o-3-master/gradle/README.md\n",
      "h2o-3-master/h2o-algos/src/main/java/hex/deeplearning/README.md\n",
      "h2o-3-master/h2o-assemblies/main/README.md\n",
      "h2o-3-master/h2o-assemblies/minimal/README.md\n",
      "h2o-3-master/h2o-bindings/bin/readme.md\n",
      "h2o-3-master/h2o-clustering/README.md\n",
      "h2o-3-master/h2o-core/src/main/resources/docs/pieces/columnSummary.md\n",
      "h2o-3-master/h2o-dist/README.md\n",
      "h2o-3-master/h2o-docs/README.md\n",
      "h2o-3-master/h2o-docs/StyleGuide.md\n",
      "h2o-3-master/h2o-docs/src/api/README.md\n",
      "h2o-3-master/h2o-docs/src/api/REST/h2o_3_rest_api_overview.md\n",
      "h2o-3-master/h2o-docs/src/api/data-science-example-1/README.md\n",
      "h2o-3-master/h2o-docs/src/api/data-science-example-1/example-flow.md\n",
      "h2o-3-master/h2o-docs/src/api/rest-api-error-handling/README.md\n",
      "h2o-3-master/h2o-docs/src/booklets/source/DeepWaterBookletErrata.md\n",
      "h2o-3-master/h2o-docs/src/booklets/v2_2015/source/LaTeX_StyleGuide.md\n",
      "h2o-3-master/h2o-docs/src/cheatsheets/H2O_R_Python_Parity.md\n",
      "h2o-3-master/h2o-docs/src/cheatsheets/Python_H2OFrame_PandasDataFrame_Parity.md\n",
      "h2o-3-master/h2o-docs/src/dev/README.md\n",
      "h2o-3-master/h2o-docs/src/dev/custom_functions.md\n",
      "h2o-3-master/h2o-docs/src/dev/lifecycle.md\n",
      "h2o-3-master/h2o-docs/src/front/README.md\n",
      "h2o-3-master/h2o-docs/src/front/assets/fonts/Heebo/README.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/README.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/RecentChanges.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/SiteIntro.md\n",
      "h2o-3-master/h2o-docs/src/product/flow/packs/examples/readme.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/Connecting_RStudio_to_Sparkling_Water.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/DemosAndTests.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/FAQ.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevCmdLine.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevDocker.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevHadoop.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevLogs.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-DevS3Creds.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/H2O-Networking.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/LDAP.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/MOJO_QuickStart.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/POJO_QuickStart.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/Videos.md\n",
      "h2o-3-master/h2o-docs/src/product/howto/YARN_BP.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/GainsLift.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/GridSearch.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/Interactions.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/datascience/DataScienceH2O-Dev.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/dl/dl.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/gbm/gbm.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/glm/glm.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/glossary.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/kmeans/kmeans.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/pca/pca.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/random hyperparmeter search and roadmap.md\n",
      "h2o-3-master/h2o-docs/src/product/tutorials/rf/rf.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/H2OBenefits.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/H2ODevPortingRScripts.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/JavaChanges.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/Migration.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/PressRelease.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/PythonParity.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/RChanges.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/Rdoc.md\n",
      "h2o-3-master/h2o-docs/src/product/upgrade/Upgrade.md\n",
      "h2o-3-master/h2o-genmodel/src/test/resources/hex/genmodel/algos/glrm/experimental/README.md\n",
      "h2o-3-master/h2o-genmodel/src/test/resources/hex/genmodel/algos/isofor/experimental/README.md\n",
      "h2o-3-master/h2o-genmodel/src/test/resources/hex/genmodel/algos/isoforextended/experimental/README.md\n",
      "h2o-3-master/h2o-k8s/README.md\n",
      "h2o-3-master/h2o-k8s/tests/clustering/README.md\n",
      "h2o-3-master/h2o-py-cloud-extensions/README.md\n",
      "h2o-3-master/h2o-py/README.md\n",
      "h2o-3-master/h2o-py/demos/README.md\n",
      "h2o-3-master/h2o-r/README.md\n",
      "h2o-3-master/h2o-r/demos/README.md\n",
      "h2o-3-master/h2o-r/ensemble/README.md\n",
      "h2o-3-master/h2o-web/README.md\n",
      "h2o-3-master/templates/gcp/README.md\n",
      "h2o-3-master/templates/gcp/network/README.md\n",
      "h2o-3-master/vagrant/README.md\n"
     ]
    }
   ],
   "source": [
    "for record in h2oai:\n",
    "    print(record['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e91e779-3920-40aa-809e-5943c9d39cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlite-master/.github/ISSUE_TEMPLATE/feature_request.md\n",
      "atlite-master/.github/pull_request_template.md\n",
      "atlite-master/CONTRIBUTING.md\n"
     ]
    }
   ],
   "source": [
    "for record in ceuriel_atlite:\n",
    "    print(record['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44860ee-be75-458e-9cf5-0fd162302309",
   "metadata": {},
   "source": [
    "#### Simple Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dbc13-3edf-4b26-a8f5-8b32e7991626",
   "metadata": {},
   "source": [
    "Applying Sliding window method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6a721f1-65a9-4882-9c1a-3ceb39b29ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60632ee8-c7ac-4a6a-b9b6-3baeda152686",
   "metadata": {},
   "source": [
    "Process the entire documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5edea32a-629d-4895-a7a9-e51b713f6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2oai_chunks = []\n",
    "\n",
    "for doc in h2oai:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    chunks = sliding_window(doc_content, 2000, 1000)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    h2oai_chunks.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7dd9d2f-4df1-4c4d-a4b2-d20df31a0f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 1639\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total chunks: {len(h2oai_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729b6d2-86d5-4640-a519-ea4f7e898907",
   "metadata": {},
   "source": [
    "#### Splitting by Paragraphs and Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772630f-03c9-4eb3-8b8d-a7dff588b106",
   "metadata": {},
   "source": [
    "splitting by paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e452c5f-431c-491f-ba17-f7b8ff6f3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = h2oai[45]['content']\n",
    "paragraphs = re.split(r\"\\n\\s*\\n\", text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447e89c-623e-4ac5-91f1-b509b379b267",
   "metadata": {},
   "source": [
    "splitting by section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df897ae4-659c-4584-983d-4910fdfde3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_markdown_by_level(text, level=2):\n",
    "    \"\"\"\n",
    "    Split markdown text by a specific header level.\n",
    "    \n",
    "    :param text: Markdown text as a string\n",
    "    :param level: Header level to split on\n",
    "    :return: List of sections as strings\n",
    "    \"\"\"\n",
    "    # This regex matches markdown headers\n",
    "    # For level 2, it matches lines starting with \"## \"\n",
    "    header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "    pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "\n",
    "    # Split and keep the headers\n",
    "    parts = pattern.split(text)\n",
    "    \n",
    "    sections = []\n",
    "    for i in range(1, len(parts), 3):\n",
    "        # We step by 3 because regex.split() with\n",
    "        # capturing groups returns:\n",
    "        # [before_match, group1, group2, after_match, ...]\n",
    "        # here group1 is \"## \", group2 is the header text\n",
    "        header = parts[i] + parts[i+1]  # \"## \" + \"Title\"\n",
    "        header = header.strip()\n",
    "\n",
    "        # Get the content after this header\n",
    "        content = \"\"\n",
    "        if i+2 < len(parts):\n",
    "            content = parts[i+2].strip()\n",
    "\n",
    "        if content:\n",
    "            section = f'{header}\\n\\n{content}'\n",
    "        else:\n",
    "            section = header\n",
    "        sections.append(section)\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7123d0-af7a-4a24-bc97-6ac8f9cd7bd1",
   "metadata": {},
   "source": [
    "Final result by iterating over all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f77be44-4738-4147-9af4-ad2c2727a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2oai_chunks = []\n",
    "\n",
    "for doc in h2oai:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    sections = split_markdown_by_level(doc_content, level=2)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        h2oai_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a64a91-8ac7-4e43-8a31-14e23d0d36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 266\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total chunks: {len(h2oai_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48085a8e-fa2b-4dde-afb5-a0f4606524e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfd76a95-6a55-48a4-b932-00a8d8488182",
   "metadata": {},
   "source": [
    "#### Intelligent Chunking with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e980788-d742-4446-8c97-a79359fd0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET API key from https://platform.openai.com/api-keys\n",
    "# create an environment variable with your key:\n",
    "# from command line run:\n",
    "# export OPENAI_API_KEY='your-api-key'\n",
    "# uv add openai\n",
    "# uv run jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a660db-488f-431c-acd1-7ab142f0628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4.1-mini'):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e2014-d31b-4d8c-bf35-610cee83ac5c",
   "metadata": {},
   "source": [
    "##### Create a prompt\n",
    "\n",
    "The prompt asks the LLM to:\n",
    "\n",
    "Split the document logically (not just by length)\n",
    "\n",
    "Make sections self-contained\n",
    "\n",
    "Use a specific output format that's easy to parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3704f58b-d993-4840-aa2b-0acd60f4d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Split the provided document into logical sections\n",
    "that make sense for a Q&A system.\n",
    "\n",
    "Each section should be self-contained and cover\n",
    "a specific topic or concept.\n",
    "\n",
    "<DOCUMENT>\n",
    "{document}\n",
    "</DOCUMENT>\n",
    "\n",
    "Use this format:\n",
    "\n",
    "## Section Name\n",
    "\n",
    "Section content with all relevant details\n",
    "\n",
    "---\n",
    "\n",
    "## Another Section Name\n",
    "\n",
    "Another section content\n",
    "\n",
    "---\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fedcd-eb05-406f-b917-9a57b60e82c3",
   "metadata": {},
   "source": [
    "##### Create a function for intelligent chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f256fd0-6882-47cc-8ea8-fde2f0529632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intelligent_chunking(text):\n",
    "    prompt = prompt_template.format(document=text)\n",
    "    response = llm(prompt)\n",
    "    sections = response.split('---')\n",
    "    sections = [s.strip() for s in sections if s.strip()]\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86853b07-c5a0-408d-9301-20fe4136244a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3684361a01487ebc6b868c04f93d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# Import your language model or define it\n",
    "# For example, if using OpenAI:\n",
    "# from openai import OpenAI\n",
    "# llm = OpenAI(api_key=\"your-api-key\")\n",
    "\n",
    "# Define the intelligent_chunking function if it's not imported from elsewhere\n",
    "def intelligent_chunking(text):\n",
    "    # Implementation of your chunking logic\n",
    "    # This is a placeholder - replace with your actual implementation\n",
    "    # that doesn't rely on an undefined llm variable\n",
    "    return [text]  # Simple implementation that returns the whole text as one chunk\n",
    "\n",
    "h2oai_chunks = []\n",
    "\n",
    "for doc in tqdm(h2oai):\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "\n",
    "    sections = intelligent_chunking(doc_content)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        h2oai_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36d33e-3e61-4bca-a267-2286288c0e1f",
   "metadata": {},
   "source": [
    "##### Apply to entire document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3eb20c1-4487-44da-b68f-afa9d59fc861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c145f942fd84027b2ad86e245cf4ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# Import your language model or define it\n",
    "# For example, if using OpenAI:\n",
    "# from openai import OpenAI\n",
    "# llm = OpenAI(api_key=\"your-api-key\")\n",
    "\n",
    "# Define the intelligent_chunking function if it's not imported from elsewhere\n",
    "def intelligent_chunking(text):\n",
    "    # Implementation of your chunking logic\n",
    "    # This is a placeholder - replace with your actual implementation\n",
    "    # that doesn't rely on an undefined llm variable\n",
    "    return [text]  # Simple implementation that returns the whole text as one chunk\n",
    "\n",
    "atlite_chunks = []\n",
    "\n",
    "for doc in tqdm(h2oai):\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "\n",
    "    sections = intelligent_chunking(doc_content)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        atlite_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaffc6d-4782-4527-86e5-66a702b96929",
   "metadata": {},
   "source": [
    "##### Note: This process requires time and incurs costs. As mentioned before, use this only when really necessary. For most applications, you don't need intelligent chunking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee746433-7219-48f7-9185-1d9320e2a85c",
   "metadata": {},
   "source": [
    "## Add Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e3174-38b7-4ac2-8f24-5c22de762ecb",
   "metadata": {},
   "source": [
    "### Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dacb5bd3-7f62-4348-9bae-237b46d98393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minsearch in /Users/macbook/anaconda3/lib/python3.11/site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in /Users/macbook/anaconda3/lib/python3.11/site-packages (from minsearch) (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/macbook/anaconda3/lib/python3.11/site-packages (from minsearch) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/macbook/anaconda3/lib/python3.11/site-packages (from minsearch) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from pandas->minsearch) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from pandas->minsearch) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from scikit-learn->minsearch) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from scikit-learn->minsearch) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from scikit-learn->minsearch) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x136037ad0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install minsearch\n",
    "\n",
    "# Index data with minsearch\n",
    "\n",
    "from minsearch import Index\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"chunk\", \"title\", \"description\", \"filename\"],\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "index.fit(h2oai_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422749b-4b3c-4492-8c35-e5dc9e28fbdd",
   "metadata": {},
   "source": [
    "#### From here we can start using our data to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43c23645-38d6-4708-a497-0d31a7343f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What should be in a test dataset for AI evaluation?'\n",
    "results = index.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3979c9-bf05-4633-ab6a-739399ff9196",
   "metadata": {},
   "source": [
    "#### For the repo h2oai h2o-3 repo, filtering through the'CONTRIBUTING' file, we search through the content text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1f85f26-3b31-4aff-9860-16387035eb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x1361e2b10>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2oai = read_repo_data('h2oai', 'h2o-3')\n",
    "md_h2oai = [d for d in h2oai if 'CONTRIBUTING' in d['filename']]\n",
    "\n",
    "h2o3_index = Index(\n",
    "    text_fields=[\"content\"],\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "h2o3_index.fit(md_h2oai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bda86f-4c8b-471a-a063-7d4969273f47",
   "metadata": {},
   "source": [
    "#### The output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "94a33281-7501-45fb-a699-f9d19e3f8681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 values: [{'content': 'Contributing to H2O\\n============================\\n\\nH2O is an open source project released under the Apache Software License v2.  Open Source projects live by their user and developer communities.  We welcome and encourage your contributions of any kind!\\n\\nThere are many different kinds of people who make use of H2O for their daily work: \\n\\n* Data Scientists who use R, Python, Scala, Java or the Flow web interface;\\n* Application Software Developers who build software to drive H2O from those languages or the REST API;\\n* Machine Learning and data munging developers, who want to extend the internal capabilities of H2O.\\n\\nNo matter what your skill set or level of engagement is with H2O you can help others by improving the ecosystem of documentation, bug report and feature request tickets, and code.\\n\\n## Bug Reports and Feature Requests\\n\\nThe single most important contribution that you can make is to report bugs and make feature requests.  The development work on H2O is largely driven by these, so please make your voice heard!  \\n\\nBug reports are most helpful if you send us a script which reproduces the problem.\\n\\nIf you\\'re a customer with an Enterprise Support contract you should send these to support@h2o.ai.\\n\\nIf you\\'re an Open Source community member you should send these to one of:\\n\\n* The h2ostream mailing list, at: [https://groups.google.com/forum/#!forum/h2ostream](https://groups.google.com/forum/#!forum/h2ostream)\\n* Gitter chat, at [https://gitter.im/h2oai/h2o-3](https://gitter.im/h2oai/h2o-3)\\n\\n### How to File Bugs and Feature Requests\\n\\nYou can file a bug report or feature request directly on the [GitHub issues](https://github.com/h2oai/h2o-3/issues) page.\\n\\nOnce inside the GitHub issues page, click the **New issue** button.\\n\\n ![create](h2o-docs/src/product/images/issue_create.png)\\n\\nA form will display allowing you to enter information about the bug or feature request.\\n\\n## Help and Documentation\\n\\nYou can help others directly and help improve the resources that others read to learn and use H2O by contributing to the formal documentation or the forums.\\n\\nThere are several places that users find information about using H2O:\\n\\n* Formal documentation, at: [http://docs.h2o.ai/](http://docs.h2o.ai/)\\n* The h2ostream mailing list, at: [https://groups.google.com/forum/#!forum/h2ostream](https://groups.google.com/forum/#!forum/h2ostream)\\n* Gitter chat, at [https://gitter.im/h2oai/h2o-3](https://gitter.im/h2oai/h2o-3)\\n* General community sites like Stack Overflow: [http://stackoverflow.com/search?q=h2o](http://stackoverflow.com/search?q=h2o)\\n* Individuals\\' blogs\\n\\n### Formal Documentation\\n\\nAll of the documentation comes directly from the source tree in GitHub.  To contribute improvements to the formal documentation you may either:\\n\\n* Send the suggestions or changes to support@h2o.ai, h2ostream or Gitter, or\\n* Use Git to make the changes yourself and submit them via a pull request (see below for details)\\n\\n### Forums\\n\\nAnswering questions for other users on h2ostream, Gitter, Stack Overflow and other forums builds the community knowledge base and is a very valuable contribution to H2O.\\n\\n### Blogs\\n\\nSome of the most interesting written materials on the use of H2O for real-world problems has been published by community members to their personal blogs.  If you\\'ve written something about H2O that you think should be more widely known contact us on h2ostream or Gitter and we will help you get the word out.\\n\\n## Tests and Demos\\n\\nThe H2O code base contains tests and demos written in R, Python, Java, Scala and Flow.  These get run as part of every build of the software, either by `gradlew build` on the development machine, or by Jenkins.  Standalone demos are conformed into xUnit tests as part of the build process.  All tests must succeed before we release a stable build.\\n\\nIf you are able to you should clone the H2O git repository, add your test case(s) there, and submit a pull request (see below).  If not, please send your code to h2ostream, Gitter or support@h2o.ai; see above for the links.\\n\\nTest directories include:\\n\\n* user-level tests in R: `h2o-r/tests/`\\n* user-level tests in Python: `h2o-py/tests/`\\n* REST API tests in Python: `py/testdir_multi_jvm/`\\n* platform tests in Java: `h2o-core/src/test/java/`\\n* algorithm tests in Java: `h2o-algos/src/test/java/`\\n* Flow tests in saved notebooks: `h2o-docs/src/product/flow/packs`\\n\\nFor Scala tests see the Sparkling Water GitHub repo.\\n\\n## Contribute Code!\\n\\nYou can contribute R, Python, Java or Scala code for H2O, either for bug fixes or new features.  If you have your own idea about what to work on a good place to begin is to discuss it with us on [Gitter](https://gitter.im/h2oai/h2o-3) so that we can help point you in the right direction.\\n\\nFor ideas about what to work on see the H2O-3 [GitHub issues](https://github.com/h2oai/h2o-3/issues).\\n\\nTo contribute code, fork the H2O-3 GitHub repo, create a branch for your work and when you\\'re done, create a pull request.  Once a PR has been created, it will trigger the H2O-3 Jenkins test system and should start automatically running tests (this will show up in the comment history on the PR).  Make sure all the tests pass.  A few notes:\\n\\n* If there\\'s not already a GitHub issue associated with this task, please create one.\\n* If there is a GitHub issue associated with your changes, choose a branch name that includes that  number.  e.g. `gh-1234_new_pca`\\n* New code must come with unit tests.  Here are some examples of [runits](https://github.com/h2oai/h2o-3/tree/master/h2o-r/tests), [pyunits](https://github.com/h2oai/h2o-3/tree/master/h2o-py/tests) and [JUnits](https://github.com/h2oai/h2o-3/tree/master/h2o-algos/src/test/java/hex) to help get you started.\\n* Use the GitHub number in the PR title.  e.g. \"GH-1234: Added new `pca_method` option in the PCA algorithm\".\\n* Write a summary of all changes & additions to the code in the PR description and add a link to the GitHub issue.', 'filename': 'h2o-3-master/CONTRIBUTING.md'}]\n"
     ]
    }
   ],
   "source": [
    "print (\"First 10 values:\", md_h2oai[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64956724-8d11-49b0-a6ed-43d975231737",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76ee8cd0-9cbf-4481-a724-22abeca227af",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e4b51ee8-0d06-4907-ba35-d9c3ed24ebef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/macbook/anaconda3/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: tqdm in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.31.4)\n",
      "Requirement already satisfied: Pillow in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/macbook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/macbook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy in /Users/macbook/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/macbook/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# install sentence-transformers\n",
    "\n",
    "!pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('multi-qa-distilbert-cos-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a41c93-6c4f-4e73-aa94-1c410816735d",
   "metadata": {},
   "source": [
    "##### turn document into vector embedding with sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "331603fc-8bc2-4df7-ab99-1fe2f3aa5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = h2oai[2]\n",
    "text = record['content']\n",
    "v_doc = embedding_model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "292b65b6-8b81-456e-b5df-98a171bc4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import and initialize the embedding model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the embedding model (using a common model as example)\n",
    "embedding_model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
    "\n",
    "# Now use the model\n",
    "query = \"We welcome and encourage your contributions of any kind!\"\n",
    "v_query = embedding_model.encode(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b783076-0bc3-458c-995a-bc8108ac1303",
   "metadata": {},
   "source": [
    "##### compute similarity between query and document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1d079ed5-5afe-44a2-8380-a309e93082be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize one of the vectors to match the other\n",
    "# For example, if you want to truncate v_doc to match v_query's size:\n",
    "v_doc_resized = v_doc[:768]  # Take only the first 768 dimensions\n",
    "similarity = v_query.dot(v_doc_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a9d277-e0a1-404e-b579-83c91fc10de7",
   "metadata": {},
   "source": [
    "##### compute similarity between query and document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e467443c-f565-4fcd-b443-2917b4ae60d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c72df1b539f499bbdafa0095ee928eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "h2o3_embeddings = []\n",
    "\n",
    "for d in tqdm(md_h2oai):\n",
    "    text = d['content']\n",
    "    v = embedding_model.encode(text)\n",
    "    h2o3_embeddings.append(v)\n",
    "\n",
    "h2o3_embeddings = np.array(h2o3_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8fb7cc81-bae8-4949-933d-3f0758d17f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = v_query.dot(v_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4721e-0fa1-4c46-880d-bf1c6ac659d6",
   "metadata": {},
   "source": [
    "##### using vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8c70f60-dc8a-497c-8fb9-5a90173f15b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x136492810>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import VectorSearch\n",
    "\n",
    "h2o3_vindex = VectorSearch(\n",
    "    keyword_fields=[]\n",
    ")\n",
    "h2o3_vindex.fit(h2o3_embeddings, md_h2oai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31456909-fdf9-48f3-86cc-460ef97f6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'We welcome and encourage your contributions of any kind!'\n",
    "q = embedding_model.encode(query)\n",
    "results = h2o3_vindex.search(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446ad4a-0ffc-4ecf-9779-ef551e8fd719",
   "metadata": {},
   "source": [
    "##### applying thesame to atlite document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b513d1c-4843-4841-ac0a-efed2b53596a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b3950e93b34d7fb61c321af223ba5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x136486a10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlite_embeddings = []\n",
    "\n",
    "for d in tqdm(atlite_chunks):\n",
    "    # Check if 'chunk' key exists in the dictionary\n",
    "    # If not, you need to use the correct key that contains the text to encode\n",
    "    # For example, if the text is stored under 'text' key instead:\n",
    "    v = embedding_model.encode(query)\n",
    "    atlite_embeddings.append(v)\n",
    "\n",
    "atlite_embeddings = np.array(atlite_embeddings)\n",
    "\n",
    "atlite_vindex = VectorSearch(\n",
    "        keyword_fields=[]\n",
    "\n",
    ")\n",
    "atlite_vindex.fit(atlite_embeddings, atlite_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff68484-2458-4a07-b740-33c0e39fd6be",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7213563d-b376-48c4-a734-faf58ed936d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'We welcome and encourage your contributions of any kind!'\n",
    "\n",
    "text_results = h2o3_index.search(query, num_results=5)\n",
    "\n",
    "q = embedding_model.encode(query)\n",
    "vector_results = h2o3_vindex.search(q, num_results=5)\n",
    "\n",
    "final_results = text_results + vector_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb65ac-67be-4a7b-895a-052aaef8379c",
   "metadata": {},
   "source": [
    "#### bringing all code into different functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fa8142d4-d0b6-401f-81fb-496cad478639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_search(query):\n",
    "    return h2o3_index.search(query, num_results=5)\n",
    "\n",
    "def vector_search(query):\n",
    "    q = embedding_model.encode(query)\n",
    "    return h2o3_vindex.search(q, num_results=5)\n",
    "\n",
    "def hybrid_search(query):\n",
    "    text_results = text_search(query)\n",
    "    vector_results = vector_search(query)\n",
    "    \n",
    "    # Combine and deduplicate results\n",
    "    seen_ids = set()\n",
    "    combined_results = []\n",
    "\n",
    "    for result in text_results + vector_results:\n",
    "        if result['filename'] not in seen_ids:\n",
    "            seen_ids.add(result['filename'])\n",
    "            combined_results.append(result)\n",
    "    \n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bea725-6024-4848-a9c0-5261e84f4286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
